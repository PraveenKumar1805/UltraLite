{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".dbc file created: UltraLite.dbc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cantools\n",
    "\n",
    "def parse_excel_spec(excel_file):\n",
    "    \"\"\"Parse the Excel specification file.\"\"\"\n",
    "    df = pd.read_excel(excel_file)  # Read the Excel file into a DataFrame\n",
    "    messages = []  # List to store messages\n",
    "    signals = {}   # Dictionary to store signals, keyed by message ID\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Type'] == 'Message':\n",
    "            try:\n",
    "                # Convert hexadecimal string to integer for the CAN ID\n",
    "                message_id = int(str(row['CAN ID']), 16)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping row {index + 1}: Invalid hexadecimal ID value '{row['CAN ID']}'\")\n",
    "                continue\n",
    "            \n",
    "            # Extract message details, with default values if columns are missing or NaN\n",
    "            dlc = int(row['DLC']) if 'DLC' in df.columns and not pd.isna(row['DLC']) else 8\n",
    "            cycle_time = int(row['Cycle Time']) if 'Cycle Time' in df.columns and not pd.isna(row['Cycle Time']) else None\n",
    "            bms1 = row['BMS1'] if 'BMS1' in df.columns and not pd.isna(row['BMS1']) else ''\n",
    "            bms2 = row['BMS2'] if 'BMS2' in df.columns and not pd.isna(row['BMS2']) else ''\n",
    "            cluster = row['Cluster'] if 'Cluster' in df.columns and not pd.isna(row['Cluster']) else ''\n",
    "            mcu = row['MCU'] if 'MCU' in df.columns and not pd.isna(row['MCU']) else ''\n",
    "            obc = row['OBC'] if 'OBC' in df.columns and not pd.isna(row['OBC']) else ''\n",
    "            tcu = row['TCU'] if 'TCU' in df.columns and not pd.isna(row['TCU']) else ''\n",
    "            comment = row['Comments'] if 'Comments' in df.columns and not pd.isna(row['Comments']) else ''\n",
    "            \n",
    "            # Determine transmitters and receivers based on BMS1, BMS2, Cluster, MCU, OBC, and TCU values\n",
    "            transmitters = []\n",
    "            receivers = []\n",
    "            if bms1 == 'Tx':\n",
    "                transmitters.append('BMS1')\n",
    "            if bms1 == 'Rx':\n",
    "                receivers.append('BMS1')\n",
    "            if bms2 == 'Tx':\n",
    "                transmitters.append('BMS2')\n",
    "            if bms2 == 'Rx':\n",
    "                receivers.append('BMS2')\n",
    "            if cluster == 'Tx':\n",
    "                transmitters.append('Cluster')\n",
    "            if cluster == 'Rx':\n",
    "                receivers.append('Cluster')\n",
    "            if mcu == 'Tx':\n",
    "                transmitters.append('MCU')\n",
    "            if mcu == 'Rx':\n",
    "                receivers.append('MCU')\n",
    "            if obc == 'Tx':\n",
    "                transmitters.append('OBC')\n",
    "            if obc == 'Rx':\n",
    "                receivers.append('OBC')\n",
    "            if tcu == 'Tx':\n",
    "                transmitters.append('TCU')\n",
    "            if tcu == 'Rx':\n",
    "                receivers.append('TCU')\n",
    "\n",
    "            # Append the message details to the messages list\n",
    "            messages.append({\n",
    "                'message_id': message_id,\n",
    "                'name': row['Message/Signal Name'],\n",
    "                'type': row['Message Type'],\n",
    "                'dlc': dlc,\n",
    "                'cycle_time': cycle_time,\n",
    "                'transmitters': transmitters,\n",
    "                'receivers': receivers,\n",
    "                'comment': comment\n",
    "            })\n",
    "        \n",
    "        elif row['Type'] == 'Signal':\n",
    "            try:\n",
    "                # Convert hexadecimal string to integer for the Message ID\n",
    "                message_id = int(str(row['Message ID']), 16)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping row {index + 1}: Invalid hexadecimal Message ID value '{row['Message ID']}'\")\n",
    "                continue\n",
    "            \n",
    "            # Extract signal values as a dictionary if present\n",
    "            signal_values = {}\n",
    "            if 'Values' in df.columns and not pd.isna(row['Values']):\n",
    "                values_str = row['Values']\n",
    "                values_pairs = values_str.split(', ')\n",
    "                for pair in values_pairs:\n",
    "                    try:\n",
    "                        key, val = pair.split('=')\n",
    "                        signal_values[int(key.strip())] = val.strip().strip('\"')\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping invalid value pair '{pair}' in row {index + 1}\")\n",
    "                        continue\n",
    "            \n",
    "            # Append the signal details to the signals dictionary\n",
    "            signals.setdefault(message_id, []).append({\n",
    "                'name': row['Message/Signal Name'],\n",
    "                'start_bit': int(row['Start Bit']),\n",
    "                'length': int(row['Length']),\n",
    "                'is_little_endian': bool(row['Little Endian']),\n",
    "                'is_signed': bool(row['Signed']),\n",
    "                'scale': float(row['Factor']),\n",
    "                'offset': float(row['Offset']),\n",
    "                'minimum': float(row['Minimum']) if 'Minimum' in df.columns and not pd.isna(row['Minimum']) else None,\n",
    "                'maximum': float(row['Maximum']) if 'Maximum' in df.columns and not pd.isna(row['Maximum']) else None,\n",
    "                'unit': row['Unit'] if 'Unit' in df.columns and not pd.isna(row['Unit']) else None,\n",
    "                'values': signal_values,  # Assign value enumerations\n",
    "                'comment': row['Comments'] if 'Comments' in df.columns and not pd.isna(row['Comments']) else ''\n",
    "            })\n",
    "\n",
    "    return messages, signals\n",
    "\n",
    "def calculate_dlc(signals):\n",
    "    \"\"\"Calculate the Data Length Code (DLC) based on the signals.\"\"\"\n",
    "    max_start_bit = max(signal['start_bit'] + signal['length'] for signal in signals)\n",
    "    return (max_start_bit + 7) // 8  # Calculate the required number of bytes\n",
    "\n",
    "def create_dbc(messages, signals):\n",
    "    \"\"\"Create a CAN database object using cantools.\"\"\"\n",
    "    message_definitions = []\n",
    "    \n",
    "    # Add messages and signals to the list\n",
    "    for message_data in messages:\n",
    "        message_id = message_data['message_id']\n",
    "        dlc = message_data['dlc']  # Use provided DLC\n",
    "        if dlc is None:  # If DLC is not provided, calculate it\n",
    "            dlc = calculate_dlc(signals.get(message_id, []))\n",
    "        \n",
    "        # Create a CAN message definition\n",
    "        message = cantools.db.Message(\n",
    "            frame_id=message_id,\n",
    "            name=message_data['name'],\n",
    "            length=dlc,\n",
    "            senders=message_data['transmitters'],  # List of transmitters\n",
    "            is_extended_frame=False,  # Modify if needed\n",
    "            cycle_time=message_data['cycle_time'],  # Cycle time if available\n",
    "            signals=[],  # Provide an empty list for signals\n",
    "            comment=message_data['comment'],  # Add comments\n",
    "            bus_name=None,  # Add bus name if needed\n",
    "            strict=True  # Strict checking of the signal start bits and lengths\n",
    "        )\n",
    "        \n",
    "        # Add signals to the message\n",
    "        for signal_data in signals.get(message_id, []):\n",
    "            signal = cantools.db.Signal(\n",
    "                name=signal_data['name'],\n",
    "                start=signal_data['start_bit'],\n",
    "                length=signal_data['length'],\n",
    "                byte_order='little_endian' if signal_data['is_little_endian'] else 'big_endian',\n",
    "                is_signed=signal_data['is_signed'],  # Use the new 'is_signed' field\n",
    "                receivers=message_data['receivers'],  # Add list of receivers\n",
    "                minimum=signal_data['minimum'],  # Add minimum value\n",
    "                maximum=signal_data['maximum'],  # Add maximum value\n",
    "                unit=signal_data['unit'],  # Add unit\n",
    "                comment=signal_data['comment'],  # Add comments\n",
    "            )\n",
    "            # Set additional signal properties\n",
    "            signal.scale = signal_data['scale']  # Add scale factor to signal\n",
    "            signal.offset = signal_data['offset']  # Add offset to signal\n",
    "            signal.choices = signal_data['values']  # Add value enumerations\n",
    "            message.signals.append(signal)\n",
    "        \n",
    "        message_definitions.append(message)\n",
    "\n",
    "    # Create the CAN database with the message definitions\n",
    "    db = cantools.db.Database(messages=message_definitions)\n",
    "    return db\n",
    "\n",
    "def save_dbc_file(db, dbc_file):\n",
    "    \"\"\"Save the CAN database to a .dbc file.\"\"\"\n",
    "    with open(dbc_file, 'w') as f:\n",
    "        f.write(db.as_dbc_string())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    excel_file = r\"D:\\EM\\UltraLite\\UltraLite\\Ultra_Lite.xlsx\"\n",
    "    dbc_file = 'UltraLite.dbc'\n",
    "\n",
    "    # Step 1: Parse the Excel specification file\n",
    "    messages, signals = parse_excel_spec(excel_file)\n",
    "\n",
    "    # Step 2: Create a CAN database object\n",
    "    db = create_dbc(messages, signals)\n",
    "\n",
    "    # Step 3: Save the CAN database to a .dbc file\n",
    "    save_dbc_file(db, dbc_file)\n",
    "\n",
    "    print(f\".dbc file created: {dbc_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
